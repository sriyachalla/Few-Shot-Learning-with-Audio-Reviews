# -*- coding: utf-8 -*-
"""Data Science Final Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1My-GIMNkD221mLGGIgg61qTS_11ukMYw
"""

!pip install openai

take1 = "So French B-stress Spa got great steak free. They've got the same name rest on a Montreal. Turns out exactly the same owner is too. Who knew? Yeah solid spa. There's nothing like amazing but cute, pretty good."
take2 = "This spot's great. They always have portrait film. Pretty good prices. Really nice guys. Best film spot in the city. Hands down."
take3 = "I'm going to say a pretty good film spot, kind of weird because you have to like check out online before coming or it takes them so long to figure it out. But they do a pretty good job, pretty consistent. Probably not the cheapest, but it's the best one I found in the area so far."
take4 = "It's like a beer garden, kind of fratty, tough to get a table. Honestly not great but like kind of fun for a party, maybe a good place to bring a whole birthday party."

import os
import openai

openai.api_key =

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('labelled_fulldata_take_df.csv', encoding = 'unicode_escape')

def get_ratings(prompt, transcription):
  completion = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": f"""
{prompt}

Here is the review: "{transcription}"
"""
    }]
  )
  return completion.choices[0].message.content

promptRating = """
The following is a transcription of an audio review of some location. Use it to rate how enjoyable the location seems on a scale of 0-10. Respond with only a number.
"""
print(get_ratings(promptRating, take1))

promptWord = """
The following is a transcription of an audio review of some location. Summarize it into just 3-4 keywords. Respond only with those words (no spaces), separated by commas.
"""
print(get_ratings(promptWord, take1))

promptModerate = """
The following is a transcription of an audio review of some location. Check if it contains any content that may be offensive according to the following guidlines.
If the review does not violate the guidlines respond with "no". If it does respodn with "yes" and give a reason why:

Guidelines:
- No Violence, Threats, Harassment, or Hateful Conduct.
- Users may not threaten other users or businesses.
- Users may not harass other users or businesses. 
- Users may not communicate malicious intent towards other users or businesses. 
- Users may not be racist, sexist, homophobic, or spread hate towards any group of people.  
- Users must be mindful of the cultural and religious sensitivities of others.
- Privacy breaches are violence.
- Users may not infringe upon the privacy of other users or businesses. Users may not publish or post other peopleâ€™s private information without their explicit consent. 
- Users may not spread falsehoods maliciously, both towards users or businesses.
- Hot Takes helps businesses by providing insights from aggregated takes. Any attempts to maliciously harm a business by a user are not allowed. 
- Users may not make up stories about businesses that paint it in a negative light if they are not true. 
- Users are not allowed to pretend to be someone else. 
- Users cannot share profanity, vulgarity, or any other form of offensive content.
- Users cannot share content that is overtly sexual or, more generally, content that is completely irrelevant to the topic at hand. 
- Users cannot post content that is illegal, violates the law, or encourages others to violate the law. 
- Users may not infringe on copyright, defame others, and must follow the laws in their jurisdiction. 
- Generative AI has made it more difficult to know whether someone is a human or AI agent online. Hot Takes is made for human users only, so any AI-led or assisted accounts are not allowed.
- AI-driven accessibility software may be allowed on a case-by-case basis.
- With the rapid advancement of generative AI, it is difficult to predict what other issues may arise in the future. Therefore we are committed to frequently reevaluating our policies and guidelines to ensure Hot Takes upholds our shared human values. 
"""
print(get_ratings(promptModerate, take1))

print(get_ratings(promptModerate, "I just set off a small fire in this pizza place. They haven't noticed yet hahahahahaha."))

print(get_ratings(promptModerate, "This place is pretty good, but the owner kinda sucks so I was thinking of getting everybody to just downvote him on google maps."))

print(get_ratings(promptModerate, "Great pizza place, I even left them a little quote-unquote surprise in their cash register. Hope it doesn't smell too bad.")) #i dont know what im implying in this review, but its clearly malicous just implicitly

df = df[0:198]

takelist = df.transcript

df

#prompts = [promptRating, promptWord, promptModerate]
ratings = []
words = []
mod = []
for take in takelist[0:60]:
  ratings.append(get_ratings(promptRating, take))
  words.append(get_ratings(promptWord, take))
  mod.append(get_ratings(promptModerate, take))

dftop = df[0:60]

dftop['score_zeroshot'] = ratings 
dftop['summary_zero'] = words 
dftop['mod_flag_zero'] = mod

dftop

ratings = []
words = []
mod = []
for take in takelist[60:120]:
  ratings.append(get_ratings(promptRating, take))
  words.append(get_ratings(promptWord, take))
  mod.append(get_ratings(promptModerate, take))

df2 = df[60:120]

df2['score_zeroshot'] = ratings 
df2['summary_zero'] = words 
df2['mod_flag_zero'] = mod

for x in df2.transcript:
  print(x)

for x in df2.mod_flag_zero:
  print(x)

df2[62:63]

ratings = []
words = []
mod = []
for take in takelist[120:200]:
  ratings.append(get_ratings(promptRating, take))
  words.append(get_ratings(promptWord, take))
  mod.append(get_ratings(promptModerate, take))

df3 = df[120:200]
df3['score_zeroshot'] = ratings 
df3['summary_zero'] = words 
df3['mod_flag_zero'] = mod

df_final = dftop.append(df2)

df_final

df_final = df_final.append(df3)

df_final.to_csv('takedf_with_gpt_responses.csv', encoding = 'unicode_escape')

"""second round with few shot"""

import pandas as pd
df=pd.read_csv('takedf_with_gpt_responses.csv',encoding='unicode_escape')

minidf = df [['transcript', 'Score','score_zeroshot']]

minidf['difference'] = abs(minidf['Score'] - minidf['score_zeroshot'])

minidf.difference.value_counts()

sorted_df = minidf.sort_values('difference', ascending=False)

sorted_df[0:10]

sorted_df.transcript[162]

sorted_df.transcript[105]

sorted_df.transcript[1]

promptRatingOneShot = """
Here is one example of a transcriptio of an audio review and an associated rating of how enjoyable the location seems from 0-1:
example 1 transcript: "Okay, so hands down the best Pilates in the city, though it\'s more strength training and it\'s not gentle and opening like regular Pilates. This Megaformer shit humbles you every time. If you need an ego dev, go to SolidCore." example 1 score: 9.
The following is a transcription of an audio review of some location. Use it to rate how enjoyable the location seems on a scale of 0-10. Respond with only a number.
"""

promptRatingTwoShot = """
Here are two examples of a transcriptio of an audio review and an associated rating of how enjoyable the location seems from 0-1:
example 1 transcript: "text" : "Okay, so hands down the best Pilates in the city, though it\'s more strength training and it\'s not gentle and opening like regular Pilates. This Megaformer shit humbles you every time. If you need an ego dev, go to SolidCore." example 2 score: 9.
example 2 transcript: "text": "Great experience with this dermatologist. I haven\'t seen one in many years. I booked something on Zofta because I had a sketchy looking mole. But she was really nice and my mole was fine so life was good." example 2 score: 9.
The following is a transcription of an audio review of some location. Use it to rate how enjoyable the location seems on a scale of 0-10. Respond with only a number.
"""

takelist = df.transcript

oneshot_scores = []
for take in takelist:
  oneshot_scores.append(get_ratings(promptRatingOneShot, take))

df2 = df[0:73]

df2['oneshot_scores'] = oneshot_scores

df2

oneshot_scores2 = []
for take in takelist[73:150]:
  oneshot_scores2.append(get_ratings(promptRatingOneShot, take))

df3 = df[73:150]
df3['oneshot_scores'] = oneshot_scores2

oneshot_scores3 = []
for take in takelist[150:]:
  oneshot_scores3.append(get_ratings(promptRatingOneShot, take))

df4 = df[150:]
df4['oneshot_scores'] = oneshot_scores3

df_final = df2.append(df3)

df_final = df_final.append(df4)

df_final

twoshot_scores = []
for take in takelist[0:70]:
  twoshot_scores.append(get_ratings(promptRatingTwoShot, take))

dft1 = df_final[0:20]
dft1['twoshot_scores'] = twoshot_scores

len(twoshot_scores)

twoshot_scores2 = []
for take in takelist[20:40]:
  twoshot_scores2.append(get_ratings(promptRatingTwoShot, take))
dft2 = df[20:40]
dft2['twoshot_scores'] = twoshot_scores2

twoshot_scores3 = []
for take in takelist[40:60]:
  twoshot_scores3.append(get_ratings(promptRatingTwoShot, take))
dft3 = df[40:60]
dft3['twoshot_scores'] = twoshot_scores3

dft2 = df[20:40]
dft2['twoshot_scores'] = twoshot_scores2
dft3 = df[40:60]
dft3['twoshot_scores'] = twoshot_scores3

twoshot_scores4 = []
for take in takelist[60:80]:
  twoshot_scores4.append(get_ratings(promptRatingTwoShot, take))
dft4 = df[60:80]
dft4['twoshot_scores'] = twoshot_scores4

twoshot_scores5 = []
for take in takelist[80:100]:
  twoshot_scores5.append(get_ratings(promptRatingTwoShot, take))
dft5 = df[80:100]
dft5['twoshot_scores'] = twoshot_scores5

twoshot_scores6 = []
for take in takelist[100:120]:
  twoshot_scores6.append(get_ratings(promptRatingTwoShot, take))
dft6 = df[100:120]
dft6['twoshot_scores'] = twoshot_scores6

twoshot_scores7 = []
for take in takelist[120:140]:
  twoshot_scores7.append(get_ratings(promptRatingTwoShot, take))
dft7 = df[120:140]
dft7['twoshot_scores'] = twoshot_scores7

twoshot_scores8 = []
for take in takelist[140:160]:
  twoshot_scores8.append(get_ratings(promptRatingTwoShot, take))
dft8 = df[140:160]
dft8['twoshot_scores'] = twoshot_scores8

twoshot_scores9 = []
for take in takelist[160:180]:
  twoshot_scores9.append(get_ratings(promptRatingTwoShot, take))
dft9 = df[160:180]
dft9['twoshot_scores'] = twoshot_scores9

twoshot_scores10 = []
for take in takelist[180:199]:
  twoshot_scores10.append(get_ratings(promptRatingTwoShot, take))
dft10 = df[180:199]
dft10['twoshot_scores'] = twoshot_scores10

dft1 = df_final[0:20]
dft1['twoshot_scores'] = twoshot_scores
dft2 = df_final[20:40]
dft2['twoshot_scores'] = twoshot_scores2
dft3 = df_final[40:60]
dft3['twoshot_scores'] = twoshot_scores3
dft4 = df_final[60:80]
dft4['twoshot_scores'] = twoshot_scores4
dft5 = df_final[80:100]
dft5['twoshot_scores'] = twoshot_scores5
dft6 = df_final[100:120]
dft6['twoshot_scores'] = twoshot_scores6
dft7 = df_final[120:140]
dft7['twoshot_scores'] = twoshot_scores7
dft8 = df_final[140:160]
dft8['twoshot_scores'] = twoshot_scores8
dft9 = df_final[160:180]
dft9['twoshot_scores'] = twoshot_scores9
dft10 = df_final[180:199]
dft10['twoshot_scores'] = twoshot_scores10

dff = pd.concat([dft1,dft2, dft3,dft4,dft5,dft6,dft7,dft8,dft9,dft10] )

dff

dff.to_csv('DL-csv-withGPTscores.csv', encoding='unicode-escape')

from google.colab import files
uploaded = files.upload()

import pandas as pd
df=pd.read_csv('DL-csv-withGPTscores (1).csv',encoding='unicode-escape')

df

df['twoshot_scores'][5]

from sqlalchemy.sql.expression import null
import re
twoshot_scores=[]
for score in df['twoshot_scores']:
  res = re.findall(r'\d+\.\d+', score)
  if(res==[]):
    res=re.findall(r'\d+',score)
  
  twoshot_scores.append(float(res[0]))

df['twoshot_scores']=twoshot_scores

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score

def calculate_mse(predicted_values, true_values):
    mse = np.mean((np.array(predicted_values) - np.array(true_values)) ** 2)
    return mse


predicted_values = df['score_zeroshot']
true_values = df['Score']

MSE = calculate_mse(predicted_values, true_values)
r2 = r2_score(true_values, predicted_values)
print(f"R2 Score: {r2}")
print(f"MSE: {MSE}")


plt.scatter(true_values, predicted_values,  label='Data points')
plt.plot(true_values, true_values,  label='Ideal line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs Predicted Values')
plt.legend()
plt.show()

predicted_values = df['oneshot_scores'].astype(int)
true_values = df['Score']

MSE1 = calculate_mse(predicted_values, true_values)
r21 = r2_score(true_values, predicted_values)
print(f"R2 Score: {r21}")
print(f"MSE: {MSE1}")


plt.scatter(true_values, predicted_values,  label='Data points')
plt.plot(true_values, true_values, label='Ideal line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs Predicted Values')
plt.legend()
plt.show()

predicted_values = df['twoshot_scores'].astype(int)
true_values = df['Score']

MSE2 = calculate_mse(predicted_values, true_values)
r22 = r2_score(true_values, predicted_values)
print(f"R2 Score: {r22}")
print(f"MSE: {MSE2}")


plt.scatter(true_values, predicted_values,  label='Data points')
plt.plot(true_values, true_values,  label='Ideal line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs Predicted Values')
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

predicted_values = df['score_zeroshot']
true_values = df['Score']
cm = confusion_matrix(true_values, predicted_values)

# Define class labels


# Plot confusion matrix
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix zero shot')
plt.colorbar()

predicted_values_os = df['oneshot_scores'].astype(int)
true_values = df['Score']
cm = confusion_matrix(true_values, predicted_values_os)

# Define class labels


# Plot confusion matrix
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix one shot')
plt.colorbar()

predicted_values_ts = df['twoshot_scores'].astype(int)
true_values = df['Score']
cm = confusion_matrix(true_values, predicted_values_ts)

# Define class labels


# Plot confusion matrix
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix one shot')
plt.colorbar()

values = [r2,r21,r22]
labels = ['r2 0 shot', 'r2 1 shot',  'r2 2 shot']


# Plotting the bar chart
plt.bar(range(len(values)), values, tick_label=labels)

# Adding labels and title
plt.xlabel('experiment')
plt.ylabel('R^2 Score')
plt.title('R^2 Across Experiments')

# Displaying the chart
plt.show()

values = [MSE,MSE1,MSE2]
labels = ['MSE 0 shot', 'MSE 1 shot',  'MSE 2 shot']


# Plotting the bar chart
plt.bar(range(len(values)), values, tick_label=labels)

# Adding labels and title
plt.xlabel('experiment')
plt.ylabel('MSE Score')
plt.title('MSE Across Experiments')

# Displaying the chart
plt.show()

